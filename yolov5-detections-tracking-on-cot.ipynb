{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# YOLOv5 detections + TRACKING submission made on COTS dataset\n\nTracking is a good idea, and we got it from Aleksandr Snorkin's notebook. Thanks Aleksandr Snorkin!\n\nLB:  Scoring...\n\nIf you like this work, please upvote !\n\nReferences for this notebook are listed below:\n\n[1][YoloX inference + Tracking on COTS [LB 0.539]](https://www.kaggle.com/parapapapam/yolox-inference-tracking-on-cots-lb-0-539)\n\n[2][higher resolution and confidence](https://www.kaggle.com/macxiao/higher-resolution-and-confidence)\n\n[3][Yolov5 is all you need](https://www.kaggle.com/steamedsheep/yolov5-is-all-you-need),\n\nplease upvote them also! ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom tqdm import tqdm\nimport sys\n\nsys.path.append('../input/tensorflow-great-barrier-reef')","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:27:49.745491Z","iopub.execute_input":"2022-01-29T02:27:49.746231Z","iopub.status.idle":"2022-01-29T02:27:51.271106Z","shell.execute_reply.started":"2022-01-29T02:27:49.746128Z","shell.execute_reply":"2022-01-29T02:27:51.270306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /root/.config/Ultralytics\n!cp /kaggle/input/yolov5-font/Arial.ttf /root/.config/Ultralytics/","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:27:51.273573Z","iopub.execute_input":"2022-01-29T02:27:51.273829Z","iopub.status.idle":"2022-01-29T02:27:52.73506Z","shell.execute_reply.started":"2022-01-29T02:27:51.273803Z","shell.execute_reply":"2022-01-29T02:27:52.734109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()# initialize the environment\niter_test = env.iter_test()      # an iterator which loops over the test set and sample submission","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:27:52.736987Z","iopub.execute_input":"2022-01-29T02:27:52.737492Z","iopub.status.idle":"2022-01-29T02:27:52.758924Z","shell.execute_reply.started":"2022-01-29T02:27:52.73745Z","shell.execute_reply":"2022-01-29T02:27:52.75827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.hub.load('../input/yolov5-lib-ds', \n                       'custom', \n                       path='../input/reef-baseline-fold12/l6_3600_uflip_vm5_f12_up/f1/best.pt',\n                       source='local',\n                       force_reload=True)  # local repo\nmodel.conf = 0.20","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:27:52.760876Z","iopub.execute_input":"2022-01-29T02:27:52.761336Z","iopub.status.idle":"2022-01-29T02:27:59.652837Z","shell.execute_reply.started":"2022-01-29T02:27:52.761301Z","shell.execute_reply":"2022-01-29T02:27:59.652065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# norfair dependencies\n%cd /kaggle/input/norfair031py3/\n!pip install commonmark-0.9.1-py2.py3-none-any.whl -f ./ --no-index\n!pip install rich-9.13.0-py3-none-any.whl\n\n!mkdir /kaggle/working/tmp\n!cp -r /kaggle/input/norfair031py3/filterpy-1.4.5/filterpy-1.4.5/ /kaggle/working/tmp/\n%cd /kaggle/working/tmp/filterpy-1.4.5/\n!pip install .\n!rm -rf /kaggle/working/tmp\n\n# norfair\n%cd /kaggle/input/norfair031py3/\n!pip install norfair-0.3.1-py3-none-any.whl -f ./ --no-index\n%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:27:59.65457Z","iopub.execute_input":"2022-01-29T02:27:59.655138Z","iopub.status.idle":"2022-01-29T02:29:16.335385Z","shell.execute_reply.started":"2022-01-29T02:27:59.655094Z","shell.execute_reply":"2022-01-29T02:29:16.334375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##############################################################\n#                      Tracking helpers                      #\n##############################################################\n\nimport numpy as np\nfrom norfair import Detection, Tracker\n\n# Helper to convert bbox in format [x_min, y_min, x_max, y_max, score] to norfair.Detection class\ndef to_norfair(detects, frame_id):\n    result = []\n    for x_min, y_min, x_max, y_max, score in detects:\n        xc, yc = (x_min + x_max) / 2, (y_min + y_max) / 2\n        w, h = x_max - x_min, y_max - y_min\n        result.append(Detection(points=np.array([xc, yc]), scores=np.array([score]), data=np.array([w, h, frame_id])))\n        \n    return result\n\n# Euclidean distance function to match detections on this frame with tracked_objects from previous frames\ndef euclidean_distance(detection, tracked_object):\n    return np.linalg.norm(detection.points - tracked_object.estimate)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:29:16.336992Z","iopub.execute_input":"2022-01-29T02:29:16.337269Z","iopub.status.idle":"2022-01-29T02:29:16.401188Z","shell.execute_reply.started":"2022-01-29T02:29:16.337231Z","shell.execute_reply":"2022-01-29T02:29:16.400465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tracker = Tracker(\n    distance_function=euclidean_distance, \n    distance_threshold=30,\n    hit_inertia_min=3,\n    hit_inertia_max=6,\n    initialization_delay=1,\n)\nframe_id = 0","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:29:16.402628Z","iopub.execute_input":"2022-01-29T02:29:16.403034Z","iopub.status.idle":"2022-01-29T02:29:16.407779Z","shell.execute_reply.started":"2022-01-29T02:29:16.402998Z","shell.execute_reply":"2022-01-29T02:29:16.406931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"for idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n    detects = []\n    anno = ''\n    r = model(img, size=10000, augment=True)\n    if r.pandas().xyxy[0].shape[0] == 0:\n        anno = ''\n    else:\n        for idx, row in r.pandas().xyxy[0].iterrows():\n            if row.confidence > 0.28:      \n                anno += '{} {} {} {} {} '.format(row.confidence, int(row.xmin), int(row.ymin), int(row.xmax-row.xmin), int(row.ymax-row.ymin))\n                detects.append([int(row.xmin), int(row.ymin), int(row.xmin)+int(row.xmax-row.xmin), int(row.ymin)+int(row.ymax-row.ymin), row.confidence])\n\n    tracked_objects = tracker.update(detections=to_norfair(detects, frame_id))\n    for tobj in tracked_objects:\n        bbox_width, bbox_height, last_detected_frame_id = tobj.last_detection.data\n        if last_detected_frame_id == frame_id:  # Skip objects that were detected on current frame\n            continue\n            \n        # Add objects that have no detections on current frame to predictions\n        xc, yc = tobj.estimate[0]\n        x_min, y_min = int(round(xc - bbox_width / 2)), int(round(yc - bbox_height / 2))\n        score = tobj.last_detection.scores[0]\n        anno += '{} {} {} {} {} '.format(score, x_min, y_min, bbox_width, bbox_height)\n        \n    pred_df['annotations'] = anno.strip(' ')\n    env.predict(pred_df)\n    frame_id += 1","metadata":{"execution":{"iopub.status.busy":"2022-01-29T02:29:16.409207Z","iopub.execute_input":"2022-01-29T02:29:16.409715Z","iopub.status.idle":"2022-01-29T02:29:25.518391Z","shell.execute_reply.started":"2022-01-29T02:29:16.40968Z","shell.execute_reply":"2022-01-29T02:29:25.513906Z"},"trusted":true},"execution_count":null,"outputs":[]}]}